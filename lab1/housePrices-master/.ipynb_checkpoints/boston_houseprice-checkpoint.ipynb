{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用线性回归预测波士顿房价"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性回归，即学习一个线性方程来拟合特征X与结果Y。  \n",
    "如根据房屋面积x1，房间数量x2，地理位置x3等来预测房屋的价格y。  \n",
    "所以我们要学习一个方程:  \n",
    "$y=w_1x_1+w_2x_2+w_3x_3 + b$  \n",
    "这个方程就是线性回归的$模型函数$，就是最终我们用来预测y值的函数  \n",
    "其中$w_1,w_2,w_3,b$ 就是我们要学习的参数。\n",
    "\n",
    "如何学习$w_1,w_2,w_3,b$ 呢，我们要学到怎样的$w_1,w_2,w_3,b$才能证明这个模型ok呢？  \n",
    "我们的目标是让预测值尽可能地接近真实值。设预测值为$y'$,真实值为y，我们当然是希望|y-$y'$|的值越小越好。  \n",
    "所以我们引入一个代价函数，用来衡量整体的预测值与真实值的整体差距。代价函数如下:  \n",
    "J(W,b) = $\\frac{1}{2m}\\sum_{i=1}^{m}{} (y'^{(i)}-y^{(i)})^2=\\frac{1}{2m}\\sum_{i=1}^{m}{} (W·X^{(i)}+b-y^{(i)})^2$\n",
    "\n",
    "我们的目标就是要最小化J(W,b)。最小化J(W,b)的方法就是梯度下降法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 变量说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对所用到的变量做一个统一说明，方便检查。  \n",
    "\n",
    "将$y=w_1x_1+w_2x_2+w_3x_3 + b$  改写为:  \n",
    "   $y=w_0x_0+w_1x_1+w_2x_2+w_3x_3$    \n",
    "   \n",
    "设:  \n",
    "m: 样本个数  \n",
    "n_x：特征维度  \n",
    "θ：($w_0,w_1,w_2,w_3 ...)$  \n",
    "则：  \n",
    "X的shape 为:(m,n_x+1)  \n",
    "y的shape为：(m,1)  \n",
    "θ 的shape = (n_x+1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_data = pd.read_csv(\"data/train.csv\")\n",
    "# pd_data.head()\n",
    "x, y=load_svmlight_file(\"data/housing_scale.txt\")\n",
    "y1=np.matrix(y)\n",
    "yy=np.transpose(y1)\n",
    "\n",
    "# x1=np.matrix(x)\n",
    "# xx=np.transpose(x1)\n",
    "#矩阵之间是有格式的，我们需要转换格式 y1=np.matrix(y)\n",
    "# yy=np.transpose(y1)\n",
    "xx=x.todense()\n",
    "# print(yy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506, 1)\n"
     ]
    }
   ],
   "source": [
    "# y = np.array(pd_data[\"medv\"]).reshape(-1,1)\n",
    "# X = np.array(pd_data.drop(columns=[\"medv\"],axis=1))\n",
    "# print(X.shape)\n",
    "# print(y.shape)\n",
    "# print(X)\n",
    "Y=yy\n",
    "X=xx\n",
    "# 输出矩阵的行列数\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X的大小为：(455, 13)\n",
      "tain_y的大小为：(455, 1)\n",
      "test_X的大小为：(51, 13)\n",
      "test_y的大小为：(51, 1)\n"
     ]
    }
   ],
   "source": [
    "#将数据分为训练集和测试集\n",
    "train_X,test_X,train_y,test_y = train_test_split(X,Y,test_size = 0.1,random_state = 1)\n",
    "print(f\"train_X的大小为：{train_X.shape}\")\n",
    "print(f\"tain_y的大小为：{train_y.shape}\")\n",
    "print(f\"test_X的大小为：{test_X.shape}\")\n",
    "print(f\"test_y的大小为：{test_y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "#标准化\n",
    "#mean计算均值\n",
    "#std计算标准差\n",
    "def nomalize(X,axis):\n",
    "    mean = np.mean(X,axis)\n",
    "    std = np.std(X,axis)\n",
    "    print(mean.shape)\n",
    "    return (X-mean)/std, mean,std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 13)\n",
      "(455, 14)\n",
      "(51, 14)\n"
     ]
    }
   ],
   "source": [
    "#将数据标准化\n",
    "# 每一个对应的维度坐标取平均\n",
    "train_X,mean,std = nomalize(train_X,axis=0)\n",
    "test_X = (test_X-mean)/std\n",
    "\n",
    "#插入一列全为1的表示b\n",
    "train_X = np.insert(train_X,0,1,axis=1)\n",
    "test_X = np.insert(test_X,0,1,axis=1)\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters(n):\n",
    "    theta = np.random.randn(n,1)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(y_,y):\n",
    "    m = y.shape[0]\n",
    "    cost = np.sum(np.square(y_-y))/(2*m)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度下降"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "损失函数J(·)是一个凸函数。存在极小值。  \n",
    "梯度下降所做的就是在损失函数上沿着导数方向下降，从而靠近极小值。  \n",
    "所以实现梯度下降的步骤为:  \n",
    "1.对θ求偏导:  \n",
    "    $d_θ = \\frac{d_{J(θ)}}{d_θ} = \\frac{1}{m}X·(X·θ-y)$  \n",
    "2.根据$d_θ$更新θ的值:   \n",
    "$θ = θ-αd_θ$  \n",
    "α为学习速率，人为指定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_desent(X,y,theta,learning_rate):\n",
    "    m = y.shape[0]\n",
    "    y_ = np.dot(X,theta)\n",
    "    d_theta = np.dot(X.T,y_-y)/m\n",
    "    theta = theta - learning_rate*d_theta\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测\n",
    "使用模型函数进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,theta):\n",
    "    return  np.dot(X,theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer(train_X,train_y,theta,learning_rate,steps):\n",
    "    costs = []\n",
    "    for step in range(steps):\n",
    "        theta = gradient_desent(train_X,train_y,theta,learning_rate)\n",
    "        y_ = predict(train_X,theta)\n",
    "        loss = compute_cost(y_,train_y)\n",
    "        costs.append(loss)\n",
    "        if step % 100 == 0:\n",
    "            print(f\"\\nAfter {step} step(s),cost is :{loss}\")\n",
    "    return theta,costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算正确率\n",
    "给定一个误差范围，如果预测值与真实值之差在该范围内，则表示预测准确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(y_pred,y,error_ratio):   \n",
    "    '''\n",
    "    y_pred---预测值\n",
    "    y -- 真实值\n",
    "    error_ratio ---误差范围，相比于真实值的百分比，如0.1，0.05\n",
    "    '''\n",
    "    y = y.reshape(-1,1)\n",
    "    m = y.shape[0]\n",
    "    correct_num = np.sum(np.fabs(y_pred-y) < error_ratio*y)\n",
    "    return correct_num/m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 组合到一起，训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(train_X,train_y,test_X,test_y,learning_rate=0.05,steps=1):\n",
    "    m,n_x = train_X.shape\n",
    "    print(learning_rate)\n",
    "    #初始化参数\n",
    "    theta = init_parameters(n_x)\n",
    "    theta,costs = optimizer(train_X,train_y,theta,learning_rate,steps)\n",
    "    \n",
    "    error_ratio = 0.30 # 即误差不能超过30%\n",
    "    print(\"==== 训练集验证 ====\")\n",
    "    y_pred = predict(train_X,theta)\n",
    "    corr_ratio = calc_accuracy(y_pred,train_y,error_ratio)\n",
    "    print(f\"训练集的正确率为：{corr_ratio}\")\n",
    "    \n",
    "    print(\"==== 验证集验证 ====\")\n",
    "    y_pred = predict(test_X,theta)\n",
    "    corr_ratio = calc_accuracy(y_pred,test_y,error_ratio)\n",
    "    print(f\"验证集的正确率为：{corr_ratio}\")\n",
    "    cost = compute_cost(y_pred,test_y)\n",
    "    print(f\"验证集的损失为：{cost}\")\n",
    "\n",
    "    # 绘制损失函数\n",
    "    plt.xlim(0,steps)\n",
    "    plt.plot(costs)\n",
    "    plt.xlabel(\"step(s)\")\n",
    "    plt.ylabel(\"costs\")\n",
    "    plt.show() \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09\n",
      "\n",
      "After 0 step(s),cost is :272.99802657963676\n",
      "\n",
      "After 100 step(s),cost is :11.240494148687747\n",
      "\n",
      "After 200 step(s),cost is :11.097702340884208\n",
      "\n",
      "After 300 step(s),cost is :11.073550424468175\n",
      "\n",
      "After 400 step(s),cost is :11.066815675608897\n",
      "\n",
      "After 500 step(s),cost is :11.064715083978118\n",
      "\n",
      "After 600 step(s),cost is :11.064048172340684\n",
      "\n",
      "After 700 step(s),cost is :11.06383587966357\n",
      "==== 训练集验证 ====\n",
      "训练集的正确率为：0.8703296703296703\n",
      "==== 验证集验证 ====\n",
      "验证集的正确率为：0.8627450980392157\n",
      "验证集的损失为：10.271179289268511\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "theta = model(train_X,train_y,test_X,test_y,learning_rate=0.09,steps=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里使用的是线性回归，线性增长。实际上更应该是增长到一定程度应该放缓。\n",
    "所以更应该选用类似$\\sqrt$z"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "253px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
